{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "#from PrepareData import PrepareData\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "#from PrepareData import PrepareData\n",
    "import math\n",
    "fft_size = 16777216\n",
    "time_res = 64e-6 # in seconds\n",
    "T_obs = (fft_size*time_res)/60 # in minutes is equal to 17.895 minutes\n",
    "freq_axis = np.fft.rfftfreq(fft_size, d=64e-6)\n",
    "freq_res = 1/(T_obs*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('meta_data/labels_runBB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = ''\n",
    "run = 'runBB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data chunks\n",
    "data_type = \"test\"\n",
    "indices = np.load(cur_dir + f'raw_data/{run}/{data_type}_indices.npy')\n",
    "X = np.load(cur_dir + f'raw_data/{run}/{data_type}_data.npy', mmap_mode='r')\n",
    "Y = np.zeros((len(indices),1))\n",
    "\n",
    "X_freq = np.zeros((X.shape[0],400))\n",
    "h = 1\n",
    "np.random.seed(42)\n",
    "for i in range(X.shape[0]):#2):\n",
    "    ind = indices[i]\n",
    "    z_ind = h*labels_df['z'][ind]\n",
    "    period = labels_df['new_period'][ind]\n",
    "    freq = 1/period\n",
    "    freq_ind = freq/freq_res\n",
    "\n",
    "    # choose a number in the interval\n",
    "    chunk_freq_ind = np.random.ranint(0,400)\n",
    "    z = np.abs(z_ind) \n",
    "    interval = 2*z\n",
    "    \n",
    "    start = chunk_freq_ind - z\n",
    "    end = chunk_freq_ind + z\n",
    "    if start < 0:\n",
    "        start = np.abs(start)\n",
    "        portion_ind = (interval - start)\n",
    "        portion = portion_ind/interval\n",
    "        start_chunk = freq_ind - z + start\n",
    "        end_chunk = start_chunk + 400\n",
    "    elif end > 400:\n",
    "        portion_ind = (interval - (end - 400))\n",
    "        portion = portion_ind/portion\n",
    "        end_chunk = freq_ind + z - (end - 400)\n",
    "        start_chunk = end_chunk - 400\n",
    "    elif (start > 0) and (end < 400):\n",
    "        portion = 1\n",
    "        start_chunk = freq_ind - z\n",
    "        end_chunk = start_chunk + 400\n",
    "    else:\n",
    "        print('something gone wrong with index',i,start,end)\n",
    "        sys.exit(1)\n",
    "\n",
    "    Y[i,0] = portion\n",
    "\n",
    "    X_freq[i,:] = X[i,start_chunk:end_chunk]\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # adjust as necessary\n",
    "    ax.plot(np.arange(0,400,1),X_freq[i,:])\n",
    "    print(portion)\n",
    "    # ax.axvline(Y_test[i,0],color='r',label='freq')\n",
    "    # ax.axvline(Y_test[i,0]+Y_test[i,1],color='g',label='z')\n",
    "    # ax.axvline(Y_test[i,0]-Y_test[i,1],color='g')\n",
    "    # plt.savefig(f'raw_data/runBB/pngs/test_data_fundamental_{ind}_p{period*1000:.2f}ms.png', dpi=100)  # adjust dpi as necessary\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# np.save(cur_dir + f'raw_data/{run}/test_data_variable_portions.npy',X_test_freq)\n",
    "# np.save(cur_dir + f'raw_data/{run}/test_labels_variable_portions.npy',Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"train\"\n",
    "indices = np.load(cur_dir + f'raw_data/{run}/{data_type}_indices.npy')\n",
    "X = np.load(cur_dir + f'raw_data/{run}/{data_type}_data.npy', mmap_mode='r')\n",
    "Y = np.zeros((len(indices),1))\n",
    "\n",
    "X_freq = np.zeros((X.shape[0],400))\n",
    "h = 1\n",
    "np.random.seed(42)\n",
    "for i in range(X.shape[0]):\n",
    "    ind = indices[i]\n",
    "    chunk_start = labels_df['chunk_start'][ind]\n",
    "    chunk_start_new = int(chunk_start + 800) # keep 400 index space from last signal\n",
    "    chunk_end_new = chunk_start_new + 400\n",
    "    X_freq[i,:] = X[i,chunk_start_new:chunk_end_new]\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(10, 6))  # adjust as necessary\n",
    "    # ax.plot(np.arange(0,400,1),X_freq[i,:])\n",
    "    # plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "np.save(cur_dir + f'raw_data/{run}/{data_type}_data_chunk_classifier.npy',X_freq)\n",
    "np.save(cur_dir + f'raw_data/{run}/{data_type}_labels_chunk_classifier.npy',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"val\"\n",
    "indices = np.load(cur_dir + f'raw_data/{run}/{data_type}_indices.npy')\n",
    "X = np.load(cur_dir + f'raw_data/{run}/{data_type}_data.npy', mmap_mode='r')\n",
    "Y = np.zeros((len(indices),1))\n",
    "\n",
    "X_freq = np.zeros((X.shape[0],400))\n",
    "h = 1\n",
    "np.random.seed(42)\n",
    "for i in range(X.shape[0]):\n",
    "    ind = indices[i]\n",
    "    chunk_start = labels_df['chunk_start'][ind]\n",
    "    chunk_start_new = int(chunk_start + 800) # keep 400 index space from last signal\n",
    "    chunk_end_new = chunk_start_new + 400\n",
    "    X_freq[i,:] = X[i,chunk_start_new:chunk_end_new]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # adjust as necessary\n",
    "    ax.plot(np.arange(0,400,1),X_freq[i,:])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "np.save(cur_dir + f'raw_data/{run}/{data_type}_data_chunk_classifier.npy',X_freq)\n",
    "np.save(cur_dir + f'raw_data/{run}/{data_type}_labels_chunk_classifier.npy',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chunks_1 = np.load(cur_dir + f'raw_data/{run}/train_data_chunk_classifier.npy')\n",
    "train_chunks_2 = np.load(cur_dir + f'raw_data/{run}/train_data_chunk.npy')\n",
    "train_labels_1 = np.load(cur_dir + f'raw_data/{run}/train_labels_chunk_classifier.npy')\n",
    "train_labels_2 = np.load(cur_dir + f'raw_data/{run}/train_labels_chunk.npy')\n",
    "\n",
    "# combine training data and shuffle and save as one\n",
    "train_chunks = np.concatenate((train_chunks_1,train_chunks_2),axis=0)\n",
    "train_labels = np.concatenate((train_labels_1,np.ones(train_labels_1.shape[0]).reshape(train_labels_1.shape[0],1)),axis=0)\n",
    "\n",
    "# shuffle\n",
    "np.random.seed(42)\n",
    "\n",
    "indices = np.arange(train_chunks.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_chunks = train_chunks[indices,:]\n",
    "train_labels = train_labels[indices,:]\n",
    "\n",
    "np.save(cur_dir + f'raw_data/{run}/train_data_classifier.npy',train_chunks)\n",
    "np.save(cur_dir + f'raw_data/{run}/train_labels_classifier.npy',train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chunks_1 = np.load(cur_dir + f'raw_data/{run}/test_data_chunk_classifier.npy')\n",
    "test_chunks_2 = np.load(cur_dir + f'raw_data/{run}/test_data_chunk.npy')\n",
    "test_labels_1 = np.load(cur_dir + f'raw_data/{run}/test_labels_chunk_classifier.npy')\n",
    "test_labels_2 = np.load(cur_dir + f'raw_data/{run}/test_labels_chunk.npy')\n",
    "\n",
    "# combine training data and shuffle and save as one\n",
    "test_chunks = np.concatenate((test_chunks_1,test_chunks_2),axis=0)\n",
    "test_labels = np.concatenate((test_labels_1,np.ones(test_labels_1.shape[0]).reshape(test_labels_1.shape[0],1)),axis=0)\n",
    "\n",
    "# shuffle\n",
    "np.random.seed(42)\n",
    "\n",
    "indices = np.arange(test_chunks.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "test_chunks = test_chunks[indices,:]\n",
    "test_labels = test_labels[indices,:]\n",
    "\n",
    "np.save(cur_dir + f'raw_data/{run}/test_data_classifier.npy',test_chunks)\n",
    "np.save(cur_dir + f'raw_data/{run}/test_labels_classifier.npy',test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_chunks_1 = np.load(cur_dir + f'raw_data/{run}/val_data_chunk_classifier.npy')\n",
    "val_chunks_2 = np.load(cur_dir + f'raw_data/{run}/val_data_chunk.npy')\n",
    "val_labels_1 = np.load(cur_dir + f'raw_data/{run}/val_labels_chunk_classifier.npy')\n",
    "val_labels_2 = np.load(cur_dir + f'raw_data/{run}/val_labels_chunk.npy')\n",
    "\n",
    "# combine training data and shuffle and save as one\n",
    "val_chunks = np.concatenate((val_chunks_1,val_chunks_2),axis=0)\n",
    "val_labels = np.concatenate((val_labels_1,np.ones(val_labels_1.shape[0]).reshape(val_labels_1.shape[0],1)),axis=0)\n",
    "\n",
    "# shuffle\n",
    "np.random.seed(42)\n",
    "\n",
    "indices = np.arange(val_chunks.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_chunks = val_chunks[indices,:]\n",
    "val_labels = val_labels[indices,:]\n",
    "\n",
    "np.save(cur_dir + f'raw_data/{run}/val_data_classifier.npy',val_chunks)\n",
    "np.save(cur_dir + f'raw_data/{run}/val_labels_classifier.npy',val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
